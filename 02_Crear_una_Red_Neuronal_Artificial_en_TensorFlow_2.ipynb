{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXnXLpEy82lC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joanby/tensorflow2/blob/master/Colab%203%20-%20Crear%20una%20Red%20Neuronal%20Artificial%20en%20TensorFlow%202.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJr4nMgyb9oS"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png\" />\n",
        "  Imagen cortesía de: https://www.kaggle.com/\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVF9I9v6Zipb"
      },
      "source": [
        "## Paso 1: Instalar las dependencias y configurar el entorno de GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS6fShx3Za4O",
        "outputId": "b1bf19ea-3ad9-417a-b267-9367e75f14cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.20.0 in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.20.0) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.20.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow==2.20.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow==2.20.0) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.20.0) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.8.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow==2.20.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow==2.20.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow==2.20.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow==2.20.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"tensorflow==2.20.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjlnjPnjWYFw"
      },
      "source": [
        "## Paso 2: Importar las dependencias necesarias para el proyecto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yt0-hrch6rZw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist # pyright: ignore[reportMissingImports]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_vv9AXUnZW78",
        "outputId": "97049b4c-416a-45e5-c85d-9f27b214c070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.20.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2OiUS-kWkJU"
      },
      "source": [
        "## Paso 3: Pre procesado de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdfoFiEEXYj1"
      },
      "source": [
        "### Cargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-lCgz6UC8pKT"
      },
      "outputs": [],
      "source": [
        "#Cargar el dataset Fashion Mnist que viene dentro del TensorFlow\n",
        "# En X_train van a ir cargada 60.000 imagenes\n",
        "# y_train ss un vector de clase con 10 posibles categorias de clasificacion de cada una de las imagenes\n",
        "# El X_test cargara las 10.000 imagenes\n",
        "# y_test es lo mismo pero para las imagenes de X_test\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYxeEHzDXdSs"
      },
      "source": [
        "### Normalizar las imágenes\n",
        "\n",
        "Se divide cada imagen en los conjunto de entrenamiento y  de testing entre el valor máximo de cada uno de los píxeles (255).\n",
        "\n",
        "De este modo, cada píxel se hallará en el rango [0, 1]. Al normalizar las imágenes, nos aseguramos que nuestro modelo de RNA entrenará más rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zvWzsB3G9IU8"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lo--rpqo9ZtA"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBacLmGIX0Es"
      },
      "source": [
        "### Redimensionar el dataset\n",
        "\n",
        "Como vamos a utilizar una red neuronal totalmente conectada, vamos a redimensionar los subconjuntos de entrenamiento y testing a formato de vector en lugar de en formato de matriz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Al consultar el X_train con shape vemos que tenemos un array tridimencional con 60.000 filas y con 28 * 28 correspondiente a los pixeles\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJC_2j78CYd4",
        "outputId": "e31f81db-3114-4c2e-bba8-3f4dbf3cc53d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2Tao7pom-grn"
      },
      "outputs": [],
      "source": [
        "#Como cada imagen tiene 28x28 píxeles, usamos la función reshape en todo el dataset de entrenamiento para convertirlo\n",
        "# en vectores de tamaño [-1 (todos los elementos), anchura * altura]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZJITyg3ECueq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9MbMrg9-kr_",
        "outputId": "aae0bbb8-4f70-4979-9fbd-f236feae7149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Ahora tenemos un array con 60.000 filas pero los pixeles los aplanamos en vectores/filas para obtener 784 nodos\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y_duQGtbCTTL"
      },
      "outputs": [],
      "source": [
        "#Redimensionamos el conjunto de testing del mismo modo\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5aDsaYSYmXD"
      },
      "source": [
        "## Paso 4: Construir la Red Neuronal Artificial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l30aZ6-GYtUP"
      },
      "source": [
        "### Definir el modelo\n",
        "\n",
        "Simplemente se define un objeto de modelo Sequential."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmfogzmn9kqv"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNzLOAK5Y-mR"
      },
      "source": [
        "### Añadir la primera capa totalmente conectada (capa Densa)\n",
        "\n",
        "Hyper-parametros de la capa:\n",
        "- número de unidades/neuronas: 128\n",
        "- función de activación: ReLU\n",
        "- input_shape: (784, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBsfDyGE-FX5"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwqx1wZUa1rH"
      },
      "source": [
        "### Añadir una capa de Dropout\n",
        "\n",
        "Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAmpLPlr-pOX"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGqvyDvNbzwN"
      },
      "source": [
        "### Añadir la segunda capa (capa de salida)\n",
        "\n",
        "- unidades: número de clases (10 en el caso del Fashion MNIST)\n",
        "- función de activación: 'softmax' (probabilidades de cada clase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmkUuF9Y-3mG"
      },
      "outputs": [],
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRsMjsvcOua"
      },
      "source": [
        "### Compilar el modelo\n",
        "\n",
        "- Optimizer: Adam\n",
        "- Loss: Sparse softmax (categorical) crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbW3xeRK_CrN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dQOL_EtChrN"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kxIIFU1cany"
      },
      "source": [
        "### Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-_oLiE0_3A2"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj23nxmtcrhd"
      },
      "source": [
        "### Evaluación del modelo y predicción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nQCioOmAL7i"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozv2YVlxcx1h"
      },
      "outputs": [],
      "source": [
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Noi53-uq9yhl"
      },
      "source": [
        "## Paso 5 : Guardar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMFm-Z9I99R5"
      },
      "source": [
        "### Guardar la arquitectura (topoligía) de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT7pmXWO9xxM"
      },
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"fashion_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UDk8L4A-CQX"
      },
      "source": [
        "### Guardar los pesos de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0ZOVcC498Mp"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"fashion_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}